{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3993,
     "status": "ok",
     "timestamp": 1700750274821,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "xJv6cXsNDWmc"
   },
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1700750274821,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "x5bYs_uODlvS"
   },
   "outputs": [],
   "source": [
    "# Defining Number of classes and image input size\n",
    "num_classes = 4\n",
    "image_height, image_width = (224,224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPT5wSt2GJmd"
   },
   "source": [
    "## Creating our first set of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24264,
     "status": "ok",
     "timestamp": 1700750299816,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "B3TWIlWl1s26",
    "outputId": "fd719ae8-c18a-4dac-8796-5fa2bb532dde"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7mZINKUPERT"
   },
   "source": [
    "Generating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4461,
     "status": "ok",
     "timestamp": 1700567684992,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "fK67fr2ODrB8",
    "outputId": "8dbbbdfc-1456-4ae5-d307-505526143189"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/train_sorted'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\calvi\\NUS ISS\\Sem 2\\Machine Learning\\09 Team Project\\model_training.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     validDataSet \u001b[39m=\u001b[39m datagen\u001b[39m.\u001b[39mflow_from_directory(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         target_size\u001b[39m=\u001b[39m(image_height, image_width),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         directory\u001b[39m=\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m filepath,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         batch_size \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m trainDataSet, validDataSet\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m trainDataSet,validDataSet \u001b[39m=\u001b[39m generateTrainValidSets(datagen, \u001b[39m\"\u001b[39;49m\u001b[39mtrain_sorted\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\calvi\\NUS ISS\\Sem 2\\Machine Learning\\09 Team Project\\model_training.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgenerateTrainValidSets\u001b[39m(datagen, filepath):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     trainDataSet \u001b[39m=\u001b[39m datagen\u001b[39m.\u001b[39;49mflow_from_directory(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         target_size\u001b[39m=\u001b[39;49m(image_height, image_width),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         directory\u001b[39m=\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/\u001b[39;49m\u001b[39m\"\u001b[39;49m \u001b[39m+\u001b[39;49m filepath,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         subset \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         class_mode \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mcategorical\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         shuffle \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         batch_size \u001b[39m=\u001b[39;49m \u001b[39m8\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     validDataSet \u001b[39m=\u001b[39m datagen\u001b[39m.\u001b[39mflow_from_directory(\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         target_size\u001b[39m=\u001b[39m(image_height, image_width),\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         directory\u001b[39m=\u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m filepath,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         batch_size \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X10sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m trainDataSet, validDataSet\n",
      "File \u001b[1;32mc:\\Users\\calvi\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\preprocessing\\image.py:1650\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_directory\u001b[1;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflow_from_directory\u001b[39m(\n\u001b[0;32m   1565\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   1566\u001b[0m     directory,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1580\u001b[0m     keep_aspect_ratio\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   1581\u001b[0m ):\n\u001b[0;32m   1582\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Takes the path to a directory & generates batches of augmented data.\u001b[39;00m\n\u001b[0;32m   1583\u001b[0m \n\u001b[0;32m   1584\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1648\u001b[0m \u001b[39m            and `y` is a numpy array of corresponding labels.\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1650\u001b[0m     \u001b[39mreturn\u001b[39;00m DirectoryIterator(\n\u001b[0;32m   1651\u001b[0m         directory,\n\u001b[0;32m   1652\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1653\u001b[0m         target_size\u001b[39m=\u001b[39;49mtarget_size,\n\u001b[0;32m   1654\u001b[0m         color_mode\u001b[39m=\u001b[39;49mcolor_mode,\n\u001b[0;32m   1655\u001b[0m         keep_aspect_ratio\u001b[39m=\u001b[39;49mkeep_aspect_ratio,\n\u001b[0;32m   1656\u001b[0m         classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[0;32m   1657\u001b[0m         class_mode\u001b[39m=\u001b[39;49mclass_mode,\n\u001b[0;32m   1658\u001b[0m         data_format\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdata_format,\n\u001b[0;32m   1659\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1660\u001b[0m         shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1661\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m   1662\u001b[0m         save_to_dir\u001b[39m=\u001b[39;49msave_to_dir,\n\u001b[0;32m   1663\u001b[0m         save_prefix\u001b[39m=\u001b[39;49msave_prefix,\n\u001b[0;32m   1664\u001b[0m         save_format\u001b[39m=\u001b[39;49msave_format,\n\u001b[0;32m   1665\u001b[0m         follow_links\u001b[39m=\u001b[39;49mfollow_links,\n\u001b[0;32m   1666\u001b[0m         subset\u001b[39m=\u001b[39;49msubset,\n\u001b[0;32m   1667\u001b[0m         interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[0;32m   1668\u001b[0m         dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdtype,\n\u001b[0;32m   1669\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\calvi\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\keras\\preprocessing\\image.py:563\u001b[0m, in \u001b[0;36mDirectoryIterator.__init__\u001b[1;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[0;32m    562\u001b[0m     classes \u001b[39m=\u001b[39m []\n\u001b[1;32m--> 563\u001b[0m     \u001b[39mfor\u001b[39;00m subdir \u001b[39min\u001b[39;00m \u001b[39msorted\u001b[39m(os\u001b[39m.\u001b[39;49mlistdir(directory)):\n\u001b[0;32m    564\u001b[0m         \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misdir(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(directory, subdir)):\n\u001b[0;32m    565\u001b[0m             classes\u001b[39m.\u001b[39mappend(subdir)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/train_sorted'"
     ]
    }
   ],
   "source": [
    "# Inputing images using ImageDataGenerator without augmentation to get baseline\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "def generateTrainValidSets(datagen, filepath):\n",
    "    trainDataSet = datagen.flow_from_directory(\n",
    "        target_size=(image_height, image_width),\n",
    "        directory=r\"/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/\" + filepath,\n",
    "        subset = \"training\",\n",
    "        class_mode = \"categorical\",\n",
    "        shuffle = True,\n",
    "        batch_size = 8\n",
    "    )\n",
    "\n",
    "    validDataSet = datagen.flow_from_directory(\n",
    "        target_size=(image_height, image_width),\n",
    "        directory=r\"/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/\" + filepath,\n",
    "        subset = \"validation\",\n",
    "        class_mode = \"categorical\",\n",
    "        shuffle = True,\n",
    "        batch_size = 8\n",
    "    )\n",
    "\n",
    "    return trainDataSet, validDataSet\n",
    "\n",
    "trainDataSet,validDataSet = generateTrainValidSets(datagen, \"train_sorted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BvQOQL_burvJ"
   },
   "outputs": [],
   "source": [
    "firstmodel = Sequential()\n",
    "\n",
    "firstmodel.add(Conv2D(64, (2, 2), activation='relu', padding='same', input_shape=(image_height, image_width, 3)))\n",
    "firstmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "firstmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# Flatten the nodes for the last layer\n",
    "firstmodel.add(Flatten())\n",
    "firstmodel.add(Dense(32, activation='relu'))\n",
    "firstmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "firstmodel.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xXTQ5zEIux-n"
   },
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "history = firstmodel.fit(\n",
    "    trainDataSet,\n",
    "    steps_per_epoch = trainDataSet.samples // trainDataSet.batch_size,\n",
    "    epochs = num_epochs,\n",
    "    validation_data = validDataSet,\n",
    "    validation_steps = validDataSet.samples // validDataSet.batch_size,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xBCQTS6wIP1j"
   },
   "source": [
    "Saving the model and the history of the first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OXxiH1EqtE6T"
   },
   "outputs": [],
   "source": [
    "# Saving the first model\n",
    "# firstmodel.save('/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/first_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31IblgGKGmp4"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C7gYSCIlw_2h"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/first_model_history.pkl', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aL_SJQQvtp1k"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1700574364020,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "rPnQ3krTtt83",
    "outputId": "e5735438-03f0-4b23-8f6b-fce11f5cb88a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check out our train loss and test loss over epochs.\n",
    "train_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Set figure size.\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "# Generate line plot of training, testing loss over epochs.\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(test_loss, label='Testing Loss')\n",
    "\n",
    "# Set title\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 640,
     "status": "ok",
     "timestamp": 1700725076032,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "sc9wKXafUdhR",
    "outputId": "a207e85f-435d-4871-bb94-76864e41bf32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 60 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preparing the test set data generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    \"test_sorted\",\n",
    "    target_size=(image_height, image_width),\n",
    "    batch_size=1,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6BgZG2G3aUCk"
   },
   "outputs": [],
   "source": [
    "firstmodel = tf.keras.models.load_model('/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/first_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4628,
     "status": "ok",
     "timestamp": 1700579311369,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "uCTtyff-SRRk",
    "outputId": "02dad18d-724d-47ad-8b6f-2edcaceaa0e3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 100ms/step - loss: 2.6448e-04 - accuracy: 1.0000\n",
      "5/5 [==============================] - 0s 70ms/step - loss: 0.7866 - accuracy: 0.8750\n",
      "60/60 [==============================] - 1s 13ms/step - loss: 1.9202 - accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "firstmodel_trainscore = firstmodel.evaluate(trainDataSet,steps=trainDataSet.samples // trainDataSet.batch_size)\n",
    "firstmodel_validationscore = firstmodel.evaluate(validDataSet,steps=validDataSet.samples // validDataSet.batch_size)\n",
    "firstmodel_testscore = firstmodel.evaluate(test_generator,steps=test_generator.samples // test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1700579324393,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "P6vSdLaQTPtV",
    "outputId": "8a4a5e23-958c-4c12-cdb1-d7748cecc0ae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base model accuracy score for the train:  1.0\n",
      "The base model accuracy score for the validation:  0.88\n",
      "======================================================\n",
      "The base model accuracy score for the validation:  0.83\n"
     ]
    }
   ],
   "source": [
    "print(\"The base model accuracy score for the train: \",firstmodel_trainscore[1])\n",
    "print(\"The base model accuracy score for the validation: \",round(firstmodel_validationscore[1],2))\n",
    "print(\"======================================================\")\n",
    "print(\"The base model accuracy score for the validation: \",round(firstmodel_testscore[1],2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOcc-0P4UUbl"
   },
   "source": [
    "As observed from evaluating the accuracy score across the 3 datasets, we notice that the model is overfitted, having a **0.85** score for the test set while having **1.00** for the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AS6wRl5TRyr"
   },
   "source": [
    "# Improving model by including dropouts, maxpooling and regularisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 3875,
     "status": "ok",
     "timestamp": 1700750373979,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "ZMg5WFrYgJoq"
   },
   "outputs": [],
   "source": [
    "secondmodel = Sequential()\n",
    "\n",
    "secondmodel.add(Conv2D(64, (2, 2), activation='relu', padding='same', input_shape=(image_height, image_width, 3)))\n",
    "secondmodel.add(Dropout(0.25))\n",
    "secondmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "secondmodel.add(Dropout(0.25))\n",
    "secondmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "secondmodel.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "secondmodel.add(Dropout(0.15))\n",
    "secondmodel.add(Flatten())\n",
    "secondmodel.add(Dense(32, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))\n",
    "secondmodel.add(Dropout(0.25))\n",
    "\n",
    "secondmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "secondmodel.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7Sji3s6GhKX"
   },
   "outputs": [],
   "source": [
    "num_epochs = 75\n",
    "history = secondmodel.fit(\n",
    "    trainDataSet,\n",
    "    steps_per_epoch = trainDataSet.samples // trainDataSet.batch_size,\n",
    "    epochs = num_epochs,\n",
    "    validation_data = validDataSet,\n",
    "    validation_steps = validDataSet.samples // validDataSet.batch_size,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ClkDocHDsufm"
   },
   "outputs": [],
   "source": [
    "# Saving the second model\n",
    "# secondmodel.save('/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/improvedmodel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MNXSrRnF9bjw"
   },
   "outputs": [],
   "source": [
    "secondmodel = tf.keras.models.load_model('/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/improvedmodel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5108,
     "status": "ok",
     "timestamp": 1700578852522,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "1zNcPt08ZD0u",
    "outputId": "2ee6bdff-678c-4019-b8eb-3140fbad7c1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 2s 74ms/step - loss: 0.4562 - accuracy: 0.9844\n",
      "5/5 [==============================] - 0s 81ms/step - loss: 0.6337 - accuracy: 0.9250\n",
      "60/60 [==============================] - 1s 14ms/step - loss: 0.8283 - accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "secondmodel_trainscore = secondmodel.evaluate(trainDataSet,steps=trainDataSet.samples // trainDataSet.batch_size)\n",
    "secondmodel_validationscore = secondmodel.evaluate(validDataSet,steps=validDataSet.samples // validDataSet.batch_size)\n",
    "secondmodel_testscore = secondmodel.evaluate(test_generator,steps=test_generator.samples // test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1700579337604,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "ljoJ77NdZSBl",
    "outputId": "e3e5f2b4-47ee-475d-ad35-c261d83ea995"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base model accuracy score for the train:  0.984375\n",
      "The base model accuracy score for the validation:  0.93\n",
      "======================================================\n",
      "The base model accuracy score for the test:  0.87\n"
     ]
    }
   ],
   "source": [
    "print(\"The base model accuracy score for the train: \",secondmodel_trainscore[1])\n",
    "print(\"The base model accuracy score for the validation: \",round(secondmodel_validationscore[1],2))\n",
    "print(\"======================================================\")\n",
    "print(\"The base model accuracy score for the test: \",round(secondmodel_testscore[1],2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LrsrChjyxfEL"
   },
   "source": [
    "Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 456,
     "status": "ok",
     "timestamp": 1700750315614,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "Fru0tBRryYtz"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700750315614,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "kSGl2iLmZkbF"
   },
   "outputs": [],
   "source": [
    "UmapwrongImageList = [\"train_sorted/banana/banana_61.jpg\",\"train_sorted/apple/apple_3.jpg\"]\n",
    "wrongImageList = [\"train_sorted/banana/banana_35.jpg\",\"train_sorted/banana/banana_61.jpg\",\"train_sorted/mixed/mixed_20.jpg\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1700749626605,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "Fjx-ZDk3yOyC"
   },
   "outputs": [],
   "source": [
    "train_sort_path = \"/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/train_sorted\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 5239,
     "status": "ok",
     "timestamp": 1700749631842,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "YmLWfoYlx17Y"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/train_sorted'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\calvi\\NUS ISS\\Sem 2\\Machine Learning\\09 Team Project\\model_training.ipynb Cell 33\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X44sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m imagedata \u001b[39m=\u001b[39m []\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X44sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m row \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X44sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m classname \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(train_sort_path):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X44sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     classpath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(train_sort_path, classname)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/calvi/NUS%20ISS/Sem%202/Machine%20Learning/09%20Team%20Project/model_training.ipynb#X44sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;00m imagepath \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mlistdir(classpath):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/train_sorted'"
     ]
    }
   ],
   "source": [
    "# Excluding outliers\n",
    "outliers = wrongImageList + UmapwrongImageList\n",
    "\n",
    "# Creating a dataframe to facilitate the flow_from_dataframe function for the ImageDataGenerator\n",
    "imagedata = []\n",
    "row = 0\n",
    "for classname in os.listdir(train_sort_path):\n",
    "    classpath = os.path.join(train_sort_path, classname)\n",
    "    for imagepath in os.listdir(classpath):\n",
    "        imagerelativepath = os.path.join(classname,imagepath)\n",
    "        if (\"train_sorted/\" + imagerelativepath) not in outliers:\n",
    "            imagedata.append([imagerelativepath, classname])\n",
    "\n",
    "\n",
    "imagedataframe = pd.DataFrame(data= imagedata, columns=(\"pathname\",\"class\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1700723175004,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "yWjvktVuyisB",
    "outputId": "8f93dd09-0a77-4fbf-f1a3-9babf73acc76"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(236, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagedataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1700619357913,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "03cDSqplykhn",
    "outputId": "aac30fb5-d0da-4241-8acc-8f199025c785"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 189 validated image filenames belonging to 4 classes.\n",
      "Found 47 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "cleaned_train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=imagedataframe,\n",
    "    directory=train_sort_path,\n",
    "    x_col='pathname',\n",
    "    y_col='class',\n",
    "    target_size=(image_height, image_width),\n",
    "    subset='training',\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    batch_size=8\n",
    ")\n",
    "\n",
    "cleaned_validation_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=imagedataframe,\n",
    "    directory=train_sort_path,\n",
    "    x_col='pathname',\n",
    "    y_col='class',\n",
    "    target_size=(image_height, image_width),\n",
    "    subset='validation',\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    batch_size=8\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 376559,
     "status": "ok",
     "timestamp": 1700619736713,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "Tn9s256Ky9rb",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "df621fde-ec9f-4f9c-ee24-297d79c8e9f3",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "17/23 [=====================>........] - ETA: 18s - loss: 7.1603 - accuracy: 0.3015"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 101s 4s/step - loss: 6.2023 - accuracy: 0.2818 - val_loss: 3.3335 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/75\n",
      "23/23 [==============================] - 3s 109ms/step - loss: 3.0428 - accuracy: 0.3812 - val_loss: 2.9360 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/75\n",
      "23/23 [==============================] - 3s 117ms/step - loss: 2.4268 - accuracy: 0.3536 - val_loss: 2.3570 - val_accuracy: 0.6750\n",
      "Epoch 4/75\n",
      "23/23 [==============================] - 3s 126ms/step - loss: 2.0184 - accuracy: 0.5359 - val_loss: 2.2010 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/75\n",
      "23/23 [==============================] - 4s 168ms/step - loss: 1.6853 - accuracy: 0.5635 - val_loss: 2.0278 - val_accuracy: 0.2500\n",
      "Epoch 6/75\n",
      "23/23 [==============================] - 3s 128ms/step - loss: 1.6004 - accuracy: 0.5746 - val_loss: 2.0957 - val_accuracy: 0.0250\n",
      "Epoch 7/75\n",
      "23/23 [==============================] - 3s 116ms/step - loss: 1.4349 - accuracy: 0.5580 - val_loss: 1.8121 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/75\n",
      "23/23 [==============================] - 3s 109ms/step - loss: 1.2714 - accuracy: 0.5967 - val_loss: 1.6691 - val_accuracy: 0.4750\n",
      "Epoch 9/75\n",
      "23/23 [==============================] - 4s 152ms/step - loss: 1.1883 - accuracy: 0.6740 - val_loss: 1.8925 - val_accuracy: 0.4500\n",
      "Epoch 10/75\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 1.3128 - accuracy: 0.6575 - val_loss: 1.5160 - val_accuracy: 0.7000\n",
      "Epoch 11/75\n",
      "23/23 [==============================] - 3s 109ms/step - loss: 1.1513 - accuracy: 0.6519 - val_loss: 0.9590 - val_accuracy: 0.9750\n",
      "Epoch 12/75\n",
      "23/23 [==============================] - 3s 146ms/step - loss: 1.0560 - accuracy: 0.7680 - val_loss: 0.9541 - val_accuracy: 0.9000\n",
      "Epoch 13/75\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 0.8802 - accuracy: 0.8232 - val_loss: 1.1640 - val_accuracy: 0.6500\n",
      "Epoch 14/75\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 1.1396 - accuracy: 0.7293 - val_loss: 1.4883 - val_accuracy: 0.6750\n",
      "Epoch 15/75\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 1.0257 - accuracy: 0.8177 - val_loss: 1.2160 - val_accuracy: 0.9250\n",
      "Epoch 16/75\n",
      "23/23 [==============================] - 3s 135ms/step - loss: 0.9592 - accuracy: 0.8011 - val_loss: 0.9282 - val_accuracy: 0.8500\n",
      "Epoch 17/75\n",
      "23/23 [==============================] - 3s 151ms/step - loss: 1.0033 - accuracy: 0.7569 - val_loss: 1.2513 - val_accuracy: 0.8500\n",
      "Epoch 18/75\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.8894 - accuracy: 0.7956 - val_loss: 0.8736 - val_accuracy: 0.9000\n",
      "Epoch 19/75\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.9491 - accuracy: 0.8508 - val_loss: 0.8852 - val_accuracy: 0.8750\n",
      "Epoch 20/75\n",
      "23/23 [==============================] - 3s 114ms/step - loss: 0.8596 - accuracy: 0.8287 - val_loss: 0.8620 - val_accuracy: 0.9750\n",
      "Epoch 21/75\n",
      "23/23 [==============================] - 4s 166ms/step - loss: 1.0047 - accuracy: 0.8287 - val_loss: 0.5236 - val_accuracy: 1.0000\n",
      "Epoch 22/75\n",
      "23/23 [==============================] - 3s 119ms/step - loss: 1.0057 - accuracy: 0.7845 - val_loss: 0.8810 - val_accuracy: 0.8500\n",
      "Epoch 23/75\n",
      "23/23 [==============================] - 3s 106ms/step - loss: 0.8746 - accuracy: 0.8398 - val_loss: 0.8340 - val_accuracy: 0.9750\n",
      "Epoch 24/75\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.8398 - accuracy: 0.8343 - val_loss: 0.5149 - val_accuracy: 1.0000\n",
      "Epoch 25/75\n",
      "23/23 [==============================] - 3s 108ms/step - loss: 0.6756 - accuracy: 0.8840 - val_loss: 0.7568 - val_accuracy: 0.8750\n",
      "Epoch 26/75\n",
      "23/23 [==============================] - 3s 141ms/step - loss: 0.6607 - accuracy: 0.8729 - val_loss: 0.4785 - val_accuracy: 0.9750\n",
      "Epoch 27/75\n",
      "23/23 [==============================] - 3s 116ms/step - loss: 0.6119 - accuracy: 0.8674 - val_loss: 0.3978 - val_accuracy: 0.9750\n",
      "Epoch 28/75\n",
      "23/23 [==============================] - 3s 115ms/step - loss: 0.6444 - accuracy: 0.8674 - val_loss: 0.7697 - val_accuracy: 0.8500\n",
      "Epoch 29/75\n",
      "23/23 [==============================] - 3s 108ms/step - loss: 0.6934 - accuracy: 0.8895 - val_loss: 0.4711 - val_accuracy: 0.9500\n",
      "Epoch 30/75\n",
      "23/23 [==============================] - 4s 158ms/step - loss: 0.8308 - accuracy: 0.8398 - val_loss: 0.4998 - val_accuracy: 1.0000\n",
      "Epoch 31/75\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.8022 - accuracy: 0.8785 - val_loss: 0.4505 - val_accuracy: 1.0000\n",
      "Epoch 32/75\n",
      "23/23 [==============================] - 3s 109ms/step - loss: 0.5883 - accuracy: 0.8950 - val_loss: 0.3384 - val_accuracy: 1.0000\n",
      "Epoch 33/75\n",
      "23/23 [==============================] - 3s 121ms/step - loss: 0.5904 - accuracy: 0.9116 - val_loss: 0.3618 - val_accuracy: 1.0000\n",
      "Epoch 34/75\n",
      "23/23 [==============================] - 4s 148ms/step - loss: 0.7663 - accuracy: 0.8785 - val_loss: 0.6712 - val_accuracy: 0.9500\n",
      "Epoch 35/75\n",
      "23/23 [==============================] - 4s 153ms/step - loss: 0.9894 - accuracy: 0.8674 - val_loss: 0.7739 - val_accuracy: 0.9500\n",
      "Epoch 36/75\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.9998 - accuracy: 0.8785 - val_loss: 0.5578 - val_accuracy: 1.0000\n",
      "Epoch 37/75\n",
      "23/23 [==============================] - 3s 115ms/step - loss: 1.0299 - accuracy: 0.8398 - val_loss: 0.6675 - val_accuracy: 0.9500\n",
      "Epoch 38/75\n",
      "23/23 [==============================] - 3s 115ms/step - loss: 0.9831 - accuracy: 0.8287 - val_loss: 0.6848 - val_accuracy: 0.9750\n",
      "Epoch 39/75\n",
      "23/23 [==============================] - 3s 134ms/step - loss: 0.8377 - accuracy: 0.8564 - val_loss: 0.4361 - val_accuracy: 1.0000\n",
      "Epoch 40/75\n",
      "23/23 [==============================] - 3s 109ms/step - loss: 0.7964 - accuracy: 0.8895 - val_loss: 0.5085 - val_accuracy: 1.0000\n",
      "Epoch 41/75\n",
      "23/23 [==============================] - 3s 142ms/step - loss: 0.6712 - accuracy: 0.9282 - val_loss: 0.5368 - val_accuracy: 0.9750\n",
      "Epoch 42/75\n",
      "23/23 [==============================] - 4s 157ms/step - loss: 0.7216 - accuracy: 0.9392 - val_loss: 0.5301 - val_accuracy: 0.9750\n",
      "Epoch 43/75\n",
      "23/23 [==============================] - 4s 154ms/step - loss: 0.9216 - accuracy: 0.8564 - val_loss: 0.6243 - val_accuracy: 1.0000\n",
      "Epoch 44/75\n",
      "23/23 [==============================] - 3s 113ms/step - loss: 1.0690 - accuracy: 0.8785 - val_loss: 0.8887 - val_accuracy: 0.9750\n",
      "Epoch 45/75\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 1.0567 - accuracy: 0.9061 - val_loss: 0.8396 - val_accuracy: 0.9750\n",
      "Epoch 46/75\n",
      "23/23 [==============================] - 3s 115ms/step - loss: 0.9991 - accuracy: 0.9227 - val_loss: 0.8189 - val_accuracy: 0.9750\n",
      "Epoch 47/75\n",
      "23/23 [==============================] - 3s 128ms/step - loss: 0.8695 - accuracy: 0.8840 - val_loss: 0.5609 - val_accuracy: 0.9750\n",
      "Epoch 48/75\n",
      "23/23 [==============================] - 4s 167ms/step - loss: 0.6992 - accuracy: 0.9006 - val_loss: 0.7393 - val_accuracy: 0.9000\n",
      "Epoch 49/75\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.8390 - accuracy: 0.8674 - val_loss: 0.7222 - val_accuracy: 0.9750\n",
      "Epoch 50/75\n",
      "23/23 [==============================] - 3s 108ms/step - loss: 0.8648 - accuracy: 0.9392 - val_loss: 0.5544 - val_accuracy: 1.0000\n",
      "Epoch 51/75\n",
      "23/23 [==============================] - 2s 109ms/step - loss: 0.6159 - accuracy: 0.9282 - val_loss: 0.3510 - val_accuracy: 1.0000\n",
      "Epoch 52/75\n",
      "23/23 [==============================] - 3s 124ms/step - loss: 0.5831 - accuracy: 0.9116 - val_loss: 0.3691 - val_accuracy: 1.0000\n",
      "Epoch 53/75\n",
      "23/23 [==============================] - 3s 147ms/step - loss: 0.6937 - accuracy: 0.9006 - val_loss: 0.6103 - val_accuracy: 0.9500\n",
      "Epoch 54/75\n",
      "23/23 [==============================] - 4s 178ms/step - loss: 0.9496 - accuracy: 0.8785 - val_loss: 0.7736 - val_accuracy: 0.9500\n",
      "Epoch 55/75\n",
      "23/23 [==============================] - 3s 108ms/step - loss: 0.7898 - accuracy: 0.9392 - val_loss: 0.4622 - val_accuracy: 1.0000\n",
      "Epoch 56/75\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.6304 - accuracy: 0.9171 - val_loss: 0.6326 - val_accuracy: 0.9500\n",
      "Epoch 57/75\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.6870 - accuracy: 0.9337 - val_loss: 0.5028 - val_accuracy: 1.0000\n",
      "Epoch 58/75\n",
      "23/23 [==============================] - 3s 129ms/step - loss: 0.6424 - accuracy: 0.9503 - val_loss: 0.7001 - val_accuracy: 0.9250\n",
      "Epoch 59/75\n",
      "23/23 [==============================] - 3s 130ms/step - loss: 0.5141 - accuracy: 0.9448 - val_loss: 0.5018 - val_accuracy: 0.9250\n",
      "Epoch 60/75\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.4234 - accuracy: 0.9613 - val_loss: 0.3400 - val_accuracy: 0.9750\n",
      "Epoch 61/75\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.6575 - accuracy: 0.9448 - val_loss: 0.8984 - val_accuracy: 0.9750\n",
      "Epoch 62/75\n",
      "23/23 [==============================] - 3s 147ms/step - loss: 1.1133 - accuracy: 0.8785 - val_loss: 1.2350 - val_accuracy: 0.8250\n",
      "Epoch 63/75\n",
      "23/23 [==============================] - 3s 112ms/step - loss: 0.9769 - accuracy: 0.9337 - val_loss: 0.6982 - val_accuracy: 1.0000\n",
      "Epoch 64/75\n",
      "23/23 [==============================] - 3s 108ms/step - loss: 0.9995 - accuracy: 0.8840 - val_loss: 1.0539 - val_accuracy: 0.8250\n",
      "Epoch 65/75\n",
      "23/23 [==============================] - 3s 153ms/step - loss: 0.9271 - accuracy: 0.9171 - val_loss: 1.8324 - val_accuracy: 0.8500\n",
      "Epoch 66/75\n",
      "23/23 [==============================] - 4s 163ms/step - loss: 0.7090 - accuracy: 0.9227 - val_loss: 0.4498 - val_accuracy: 0.9750\n",
      "Epoch 67/75\n",
      "23/23 [==============================] - 3s 98ms/step - loss: 0.6227 - accuracy: 0.9724 - val_loss: 0.4871 - val_accuracy: 1.0000\n",
      "Epoch 68/75\n",
      "23/23 [==============================] - 3s 107ms/step - loss: 0.5518 - accuracy: 0.9613 - val_loss: 0.6262 - val_accuracy: 0.9000\n",
      "Epoch 69/75\n",
      "23/23 [==============================] - 3s 110ms/step - loss: 0.6386 - accuracy: 0.9171 - val_loss: 0.8220 - val_accuracy: 0.9250\n",
      "Epoch 70/75\n",
      "23/23 [==============================] - 3s 151ms/step - loss: 0.7739 - accuracy: 0.9227 - val_loss: 1.0770 - val_accuracy: 0.9250\n",
      "Epoch 71/75\n",
      "23/23 [==============================] - 3s 120ms/step - loss: 0.7591 - accuracy: 0.9227 - val_loss: 0.6724 - val_accuracy: 0.9500\n",
      "Epoch 72/75\n",
      "23/23 [==============================] - 3s 115ms/step - loss: 0.6825 - accuracy: 0.9392 - val_loss: 0.7380 - val_accuracy: 0.9250\n",
      "Epoch 73/75\n",
      "23/23 [==============================] - 3s 111ms/step - loss: 0.5487 - accuracy: 0.9558 - val_loss: 0.8970 - val_accuracy: 0.8750\n",
      "Epoch 74/75\n",
      "23/23 [==============================] - 4s 160ms/step - loss: 0.4418 - accuracy: 0.9669 - val_loss: 0.3458 - val_accuracy: 0.9500\n",
      "Epoch 75/75\n",
      "23/23 [==============================] - 3s 148ms/step - loss: 0.4406 - accuracy: 0.9392 - val_loss: 0.4614 - val_accuracy: 0.9250\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 75\n",
    "history = secondmodel.fit(\n",
    "    cleaned_train_generator,\n",
    "    steps_per_epoch = cleaned_train_generator.samples // cleaned_train_generator.batch_size,\n",
    "    epochs = num_epochs,\n",
    "    validation_data = cleaned_validation_generator,\n",
    "    validation_steps = cleaned_validation_generator.samples // cleaned_validation_generator.batch_size,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ld9ni4phzj9e"
   },
   "outputs": [],
   "source": [
    "# Saving the third model\n",
    "#secondmodel.save('/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/cleaned_improvedmodel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26227,
     "status": "ok",
     "timestamp": 1700619958712,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "9dNL2FyE13oK",
    "outputId": "53132a8b-a80f-4776-ae5a-9d3774b5f792"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 3s 122ms/step - loss: 0.3409 - accuracy: 0.9783\n",
      "5/5 [==============================] - 1s 94ms/step - loss: 0.4528 - accuracy: 0.9250\n",
      "60/60 [==============================] - 22s 371ms/step - loss: 0.5322 - accuracy: 0.8833\n"
     ]
    }
   ],
   "source": [
    "thirdmodel_trainscore = secondmodel.evaluate(cleaned_train_generator,steps=cleaned_train_generator.samples // cleaned_train_generator.batch_size)\n",
    "thirdmodel_validationscore = secondmodel.evaluate(cleaned_validation_generator,steps=cleaned_validation_generator.samples // cleaned_validation_generator.batch_size)\n",
    "thirdmodel_testscore = secondmodel.evaluate(test_generator,steps=test_generator.samples // test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1700619962797,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "Fr8Vsu5r13ob",
    "outputId": "ca1dfdac-2bf3-4739-876b-812e3cb74b35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base model accuracy score for the train:  0.97826087474823\n",
      "The base model accuracy score for the validation:  0.93\n",
      "======================================================\n",
      "The base model accuracy score for the test:  0.88\n"
     ]
    }
   ],
   "source": [
    "print(\"The base model accuracy score for the train: \",thirdmodel_trainscore[1])\n",
    "print(\"The base model accuracy score for the validation: \",round(thirdmodel_validationscore[1],2))\n",
    "print(\"======================================================\")\n",
    "print(\"The base model accuracy score for the test: \",round(thirdmodel_testscore[1],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700750325404,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "m4BCKbWTs09h"
   },
   "outputs": [],
   "source": [
    "train_sort_path = \"additional_train_sorted\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 5168,
     "status": "ok",
     "timestamp": 1700750332102,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "koB2Gsjus09i"
   },
   "outputs": [],
   "source": [
    "# Excluding outliers\n",
    "outliers = wrongImageList + UmapwrongImageList\n",
    "\n",
    "# Creating a dataframe to facilitate the flow_from_dataframe function for the ImageDataGenerator\n",
    "imagedata = []\n",
    "row = 0\n",
    "for classname in os.listdir(train_sort_path):\n",
    "    classpath = os.path.join(train_sort_path, classname)\n",
    "    for imagepath in os.listdir(classpath):\n",
    "        imagerelativepath = os.path.join(classname,imagepath)\n",
    "        if (\"train_sorted/\" + imagerelativepath) not in outliers:\n",
    "            imagedata.append([imagerelativepath, classname])\n",
    "\n",
    "\n",
    "imagedataframe = pd.DataFrame(data= imagedata, columns=(\"pathname\",\"class\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1700750332102,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "maCeYB1M2H6W"
   },
   "outputs": [],
   "source": [
    "# Defining our augmentation parameters\n",
    "augmenteddatagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 598,
     "status": "ok",
     "timestamp": 1700750332698,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "MhhSMDrngMjT",
    "outputId": "07c3691a-a04a-4563-e208-83c17e984d52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 733 validated image filenames belonging to 4 classes.\n",
      "Found 183 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "augmented_train_generator = augmenteddatagen.flow_from_dataframe(\n",
    "    dataframe=imagedataframe,\n",
    "    directory=train_sort_path,\n",
    "    x_col='pathname',\n",
    "    y_col='class',\n",
    "    target_size=(image_height, image_width),\n",
    "    subset='training',\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    batch_size=16\n",
    ")\n",
    "\n",
    "augmented_validation_generator = augmenteddatagen.flow_from_dataframe(\n",
    "    dataframe=imagedataframe,\n",
    "    directory=train_sort_path,\n",
    "    x_col='pathname',\n",
    "    y_col='class',\n",
    "    target_size=(image_height, image_width),\n",
    "    subset='validation',\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    batch_size=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 546866,
     "status": "error",
     "timestamp": 1700750924984,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "4NSvLEe4sfmF",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "b21042c7-ebdd-46cf-eeb4-256afc916b0d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "45/45 [==============================] - ETA: 0s - loss: 0.8871 - accuracy: 0.7490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calvi\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\PIL\\Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 8s 166ms/step - loss: 0.8871 - accuracy: 0.7490 - val_loss: 1.4797 - val_accuracy: 0.0511\n",
      "Epoch 2/40\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.8351 - accuracy: 0.7755 - val_loss: 1.3128 - val_accuracy: 0.3920\n",
      "Epoch 3/40\n",
      "45/45 [==============================] - 8s 181ms/step - loss: 0.8719 - accuracy: 0.7713 - val_loss: 0.7787 - val_accuracy: 0.8182\n",
      "Epoch 4/40\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.7491 - accuracy: 0.8201 - val_loss: 0.8744 - val_accuracy: 0.6648\n",
      "Epoch 5/40\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.7380 - accuracy: 0.8368 - val_loss: 0.8447 - val_accuracy: 0.8352\n",
      "Epoch 6/40\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.7094 - accuracy: 0.8382 - val_loss: 0.7959 - val_accuracy: 0.8182\n",
      "Epoch 7/40\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.7096 - accuracy: 0.8438 - val_loss: 0.8711 - val_accuracy: 0.9261\n",
      "Epoch 8/40\n",
      "45/45 [==============================] - 7s 164ms/step - loss: 0.7579 - accuracy: 0.8396 - val_loss: 0.5476 - val_accuracy: 0.9318\n",
      "Epoch 9/40\n",
      "45/45 [==============================] - 8s 166ms/step - loss: 0.7206 - accuracy: 0.8536 - val_loss: 0.9920 - val_accuracy: 0.8580\n",
      "Epoch 10/40\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.7662 - accuracy: 0.8550 - val_loss: 0.9042 - val_accuracy: 0.8239\n",
      "Epoch 11/40\n",
      "45/45 [==============================] - 8s 170ms/step - loss: 0.6784 - accuracy: 0.8801 - val_loss: 0.7519 - val_accuracy: 0.9545\n",
      "Epoch 12/40\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.6564 - accuracy: 0.8619 - val_loss: 0.7247 - val_accuracy: 0.8977\n",
      "Epoch 13/40\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.7170 - accuracy: 0.8633 - val_loss: 0.7292 - val_accuracy: 0.9034\n",
      "Epoch 14/40\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.6407 - accuracy: 0.8689 - val_loss: 0.5049 - val_accuracy: 0.9602\n",
      "Epoch 15/40\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.6437 - accuracy: 0.8842 - val_loss: 0.6288 - val_accuracy: 0.9830\n",
      "Epoch 16/40\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.7532 - accuracy: 0.8703 - val_loss: 0.5955 - val_accuracy: 0.9545\n",
      "Epoch 17/40\n",
      "45/45 [==============================] - 8s 166ms/step - loss: 0.6919 - accuracy: 0.8926 - val_loss: 0.5160 - val_accuracy: 0.9830\n",
      "Epoch 18/40\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.6208 - accuracy: 0.8884 - val_loss: 0.6955 - val_accuracy: 0.9545\n",
      "Epoch 19/40\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.6137 - accuracy: 0.8912 - val_loss: 0.8211 - val_accuracy: 0.9091\n",
      "Epoch 20/40\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.5944 - accuracy: 0.8954 - val_loss: 0.6126 - val_accuracy: 0.9091\n",
      "Epoch 21/40\n",
      "45/45 [==============================] - 8s 166ms/step - loss: 0.6151 - accuracy: 0.8801 - val_loss: 0.5131 - val_accuracy: 0.9659\n",
      "Epoch 22/40\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.5387 - accuracy: 0.8996 - val_loss: 0.8371 - val_accuracy: 0.8750\n",
      "Epoch 23/40\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.5951 - accuracy: 0.9010 - val_loss: 0.4900 - val_accuracy: 0.9489\n",
      "Epoch 24/40\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.6815 - accuracy: 0.8912 - val_loss: 0.4008 - val_accuracy: 0.9773\n",
      "Epoch 25/40\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.5774 - accuracy: 0.9010 - val_loss: 0.4834 - val_accuracy: 0.9659\n",
      "Epoch 26/40\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.5890 - accuracy: 0.9052 - val_loss: 0.4369 - val_accuracy: 0.9545\n",
      "Epoch 27/40\n",
      "45/45 [==============================] - 8s 166ms/step - loss: 0.5779 - accuracy: 0.9010 - val_loss: 0.3630 - val_accuracy: 0.9602\n",
      "Epoch 28/40\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.6744 - accuracy: 0.8954 - val_loss: 0.6996 - val_accuracy: 0.9489\n",
      "Epoch 29/40\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.6544 - accuracy: 0.8926 - val_loss: 0.7586 - val_accuracy: 0.9091\n",
      "Epoch 30/40\n",
      "45/45 [==============================] - 8s 166ms/step - loss: 0.5509 - accuracy: 0.8912 - val_loss: 0.4786 - val_accuracy: 0.9602\n",
      "Epoch 31/40\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.6303 - accuracy: 0.9024 - val_loss: 0.6642 - val_accuracy: 0.9318\n",
      "Epoch 32/40\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.5297 - accuracy: 0.9135 - val_loss: 0.8599 - val_accuracy: 0.8864\n",
      "Epoch 33/40\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.5300 - accuracy: 0.9010 - val_loss: 0.5723 - val_accuracy: 0.9545\n",
      "Epoch 34/40\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.5793 - accuracy: 0.9010 - val_loss: 0.6727 - val_accuracy: 0.9432\n",
      "Epoch 35/40\n",
      "45/45 [==============================] - 8s 168ms/step - loss: 0.5779 - accuracy: 0.9107 - val_loss: 0.5716 - val_accuracy: 0.9659\n",
      "Epoch 36/40\n",
      "45/45 [==============================] - 7s 166ms/step - loss: 0.5619 - accuracy: 0.8944 - val_loss: 0.6826 - val_accuracy: 0.9375\n",
      "Epoch 37/40\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.6459 - accuracy: 0.8912 - val_loss: 0.6530 - val_accuracy: 0.9432\n",
      "Epoch 38/40\n",
      "45/45 [==============================] - 8s 167ms/step - loss: 0.8500 - accuracy: 0.8703 - val_loss: 0.7724 - val_accuracy: 0.9261\n",
      "Epoch 39/40\n",
      "45/45 [==============================] - 8s 169ms/step - loss: 0.7559 - accuracy: 0.8884 - val_loss: 1.2345 - val_accuracy: 0.9034\n",
      "Epoch 40/40\n",
      "45/45 [==============================] - 7s 165ms/step - loss: 0.8314 - accuracy: 0.8912 - val_loss: 0.4778 - val_accuracy: 0.9659\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 40\n",
    "with tf.device('/GPU:0'):\n",
    "    history = secondmodel.fit(\n",
    "        augmented_train_generator,\n",
    "        steps_per_epoch = augmented_train_generator.samples // augmented_train_generator.batch_size,\n",
    "        epochs = num_epochs,\n",
    "        validation_data = augmented_validation_generator,\n",
    "        validation_steps = augmented_validation_generator.samples // augmented_validation_generator.batch_size,\n",
    "        verbose = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the third model\n",
    "# secondmodel.save('augmented_improvedmodel.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 86021,
     "status": "ok",
     "timestamp": 1700725162595,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "jcNsZrdcGZ5N",
    "outputId": "f50c7ac5-7987-4b7c-9f73-afc74a65002c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45/45 [==============================] - 6s 133ms/step - loss: 0.6079 - accuracy: 0.9208\n",
      "11/11 [==============================] - 1s 132ms/step - loss: 0.4831 - accuracy: 0.9659\n",
      "60/60 [==============================] - 1s 9ms/step - loss: 0.8405 - accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "fourthmodel_trainscore = secondmodel.evaluate(augmented_train_generator,steps=augmented_train_generator.samples // augmented_train_generator.batch_size)\n",
    "fourthmodel_validationscore = secondmodel.evaluate(augmented_validation_generator,steps=augmented_validation_generator.samples // augmented_validation_generator.batch_size)\n",
    "fourthmodel_testscore = secondmodel.evaluate(test_generator,steps=test_generator.samples // test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "error",
     "timestamp": 1700726043880,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "EescUqinGZ5O",
    "outputId": "7ab8b20f-7c48-44be-ede4-3a99908c773d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base model accuracy score for the train:  0.9208333492279053\n",
      "The base model accuracy score for the validation:  0.97\n",
      "======================================================\n",
      "The base model accuracy score for the test:  0.87\n"
     ]
    }
   ],
   "source": [
    "print(\"The base model accuracy score for the train: \",fourthmodel_trainscore[1])\n",
    "print(\"The base model accuracy score for the validation: \",round(fourthmodel_validationscore[1],2))\n",
    "print(\"======================================================\")\n",
    "print(\"The base model accuracy score for the test: \",round(fourthmodel_testscore[1],2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qNfDTxupFTp"
   },
   "source": [
    "From the score that we have obtained above, we are still seeing overfitting on the training set as compared to the validation and test set. We are going to attempt to improve the model with batch normalisation and increasing the nodes on the layers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 253
    },
    "executionInfo": {
     "elapsed": 350,
     "status": "error",
     "timestamp": 1700727501296,
     "user": {
      "displayName": "calvin poh",
      "userId": "01610010728414180948"
     },
     "user_tz": -480
    },
    "id": "PiS7-ZZ8Gty9",
    "outputId": "fd4df69d-65d2-4691-ca21-5fdd44604ae9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4287fd1ece6f>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mclasspath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilepaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasspath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mnum_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepaths\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf\"/{classpath}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0mimagecount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"str\") to list"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "filepaths = os.listdir(\"/content/drive/Othercomputers/New Desktop/NUS ISS/Sem 2/Machine Learning/09 Team Project/additional_train_sorted\")\n",
    "\n",
    "pattern = r\"^[^_]*\"\n",
    "imagecount = {\"apple\": 0,\"banana\": 0,\"orange\": 0, \"mixed\": 0}\n",
    "for classpath in filepaths:\n",
    "  num_images = os.listdir(filepaths + f\"/{classpath}\")\n",
    "  imagecount[classpath] = len(num_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# Defining our augmentation parameters\n",
    "augmenteddatagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "trainingpath = \"train_sorted (augmented)\"\n",
    "classes = os.listdir(trainingpath)\n",
    "\n",
    "num_images_per_class = {\n",
    "    'apple': 5,\n",
    "    'banana': 5,\n",
    "    'orange': 5,\n",
    "    'mixed': 15 \n",
    "}\n",
    "\n",
    "def augment_images(class_name, num_augmented_images):\n",
    "    class_dir = os.path.join(trainingpath, class_name)\n",
    "    for file in os.listdir(class_dir):\n",
    "        if file.endswith(('.png', '.jpg', '.jpeg')):  \n",
    "            file_path = os.path.join(class_dir, file)\n",
    "            img = load_img(file_path)\n",
    "            img_array = img_to_array(img)\n",
    "            img_array = img_array.reshape((1,) + img_array.shape)\n",
    "\n",
    "            # Generate and save the augmented images\n",
    "            i = 0\n",
    "            for batch in augmenteddatagen.flow(img_array, batch_size=1, save_to_dir=class_dir, save_prefix=class_name, save_format='jpeg'):\n",
    "                i += 1\n",
    "                if i >= num_augmented_images:\n",
    "                    break  # Break after generating the required number of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting images for class: apple\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\calvi\\anaconda3\\envs\\tensorflowgpu\\lib\\site-packages\\PIL\\Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmenting images for class: banana\n",
      "Augmenting images for class: mixed\n",
      "Augmenting images for class: orange\n"
     ]
    }
   ],
   "source": [
    "# Loop through the classes and augment images\n",
    "for class_name in classes:\n",
    "    print(f'Augmenting images for class: {class_name}')\n",
    "    augment_images(class_name, num_images_per_class[class_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "filepaths = os.listdir(\"additional_train_sorted\")\n",
    "\n",
    "imagecount = {\"apple\": 0,\"banana\": 0,\"orange\": 0, \"mixed\": 0}\n",
    "for classpath in filepaths:\n",
    "  num_images = os.listdir(\"additional_train_sorted/\" + classpath)\n",
    "  imagecount[classpath] = len(num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'apple': 1741, 'banana': 1637, 'orange': 1547, 'mixed': 626}"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagecount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the newly augmented dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 193 images belonging to 4 classes.\n",
      "Found 47 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Inputing images using ImageDataGenerator without augmentation to get baseline\n",
    "datagen = ImageDataGenerator(\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "\n",
    "trainDataSet = trainDataSet = datagen.flow_from_directory(\n",
    "    target_size=(image_height, image_width),\n",
    "    directory=\"train_sorted\",\n",
    "    subset = \"training\",\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = True,\n",
    "    batch_size = 32\n",
    ")\n",
    "\n",
    "validDataSet = validDataSet = datagen.flow_from_directory(\n",
    "    target_size=(image_height, image_width),\n",
    "    directory=\"train_sorted\",\n",
    "    subset = \"validation\",\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = True,\n",
    "    batch_size = 32\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "1OHd4uRllIzT"
   },
   "outputs": [],
   "source": [
    "# Adding batch normalisation to further reduce overfitting\n",
    "fifthmodel = Sequential()\n",
    "\n",
    "fifthmodel.add(Conv2D(32, (2, 2), activation='relu', padding='same', input_shape=(image_height, image_width, 3)))\n",
    "fifthmodel.add(BatchNormalization())\n",
    "fifthmodel.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "fifthmodel.add(Dropout(0.15))\n",
    "fifthmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "fifthmodel.add(BatchNormalization())\n",
    "fifthmodel.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "fifthmodel.add(Dropout(0.15))\n",
    "fifthmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "fifthmodel.add(BatchNormalization())\n",
    "fifthmodel.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
    "fifthmodel.add(Dropout(0.15))\n",
    "\n",
    "\n",
    "fifthmodel.add(Flatten())\n",
    "\n",
    "# FC layer\n",
    "fifthmodel.add(Dense(64, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))\n",
    "fifthmodel.add(Dropout(0.25))\n",
    "\n",
    "fifthmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "fifthmodel.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "id": "gHk4cYIZOhx7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 9s 208ms/step - loss: 7.3948 - accuracy: 0.6913 - val_loss: 8.1914 - val_accuracy: 0.3438\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 8s 198ms/step - loss: 3.5467 - accuracy: 0.8266 - val_loss: 3.4479 - val_accuracy: 0.7344\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 8s 204ms/step - loss: 3.2014 - accuracy: 0.8520 - val_loss: 12.3839 - val_accuracy: 0.4969\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 8s 204ms/step - loss: 2.6139 - accuracy: 0.8536 - val_loss: 2.8720 - val_accuracy: 0.8188\n",
      "Epoch 5/50\n",
      "40/40 [==============================] - 8s 205ms/step - loss: 2.1441 - accuracy: 0.8878 - val_loss: 2.4975 - val_accuracy: 0.8875\n",
      "Epoch 6/50\n",
      "40/40 [==============================] - 8s 209ms/step - loss: 1.9801 - accuracy: 0.8870 - val_loss: 3.4659 - val_accuracy: 0.8438\n",
      "Epoch 7/50\n",
      "40/40 [==============================] - 8s 205ms/step - loss: 1.8899 - accuracy: 0.8807 - val_loss: 2.4780 - val_accuracy: 0.8594\n",
      "Epoch 8/50\n",
      "40/40 [==============================] - 8s 204ms/step - loss: 1.6944 - accuracy: 0.8990 - val_loss: 1.5297 - val_accuracy: 0.9406\n",
      "Epoch 9/50\n",
      "40/40 [==============================] - 8s 201ms/step - loss: 1.8059 - accuracy: 0.9045 - val_loss: 2.2550 - val_accuracy: 0.8594\n",
      "Epoch 10/50\n",
      "40/40 [==============================] - 8s 201ms/step - loss: 1.9298 - accuracy: 0.8727 - val_loss: 2.4293 - val_accuracy: 0.8625\n",
      "Epoch 11/50\n",
      "40/40 [==============================] - 8s 201ms/step - loss: 1.8504 - accuracy: 0.8894 - val_loss: 1.7582 - val_accuracy: 0.9094\n",
      "Epoch 12/50\n",
      "40/40 [==============================] - 8s 198ms/step - loss: 1.6245 - accuracy: 0.8743 - val_loss: 11.6338 - val_accuracy: 0.6344\n",
      "Epoch 13/50\n",
      "40/40 [==============================] - 8s 201ms/step - loss: 1.6718 - accuracy: 0.8990 - val_loss: 2.4398 - val_accuracy: 0.7875\n",
      "Epoch 14/50\n",
      "40/40 [==============================] - 8s 201ms/step - loss: 1.8274 - accuracy: 0.9021 - val_loss: 2.6573 - val_accuracy: 0.7469\n",
      "Epoch 15/50\n",
      "40/40 [==============================] - 8s 200ms/step - loss: 2.6455 - accuracy: 0.8656 - val_loss: 3.5780 - val_accuracy: 0.8438\n",
      "Epoch 16/50\n",
      "40/40 [==============================] - 8s 203ms/step - loss: 3.4148 - accuracy: 0.8727 - val_loss: 3.0819 - val_accuracy: 0.8687\n",
      "Epoch 17/50\n",
      "40/40 [==============================] - 8s 201ms/step - loss: 2.8201 - accuracy: 0.8982 - val_loss: 2.8238 - val_accuracy: 0.8656\n",
      "Epoch 18/50\n",
      "40/40 [==============================] - 8s 201ms/step - loss: 2.8871 - accuracy: 0.8918 - val_loss: 2.4791 - val_accuracy: 0.9219\n",
      "Epoch 19/50\n",
      "40/40 [==============================] - 8s 200ms/step - loss: 2.3966 - accuracy: 0.9077 - val_loss: 3.6360 - val_accuracy: 0.8219\n",
      "Epoch 20/50\n",
      "40/40 [==============================] - 8s 200ms/step - loss: 2.2270 - accuracy: 0.8648 - val_loss: 2.5098 - val_accuracy: 0.8750\n",
      "Epoch 21/50\n",
      "40/40 [==============================] - 8s 199ms/step - loss: 1.8811 - accuracy: 0.8942 - val_loss: 1.6937 - val_accuracy: 0.9344\n",
      "Epoch 22/50\n",
      "40/40 [==============================] - 8s 199ms/step - loss: 2.0743 - accuracy: 0.9093 - val_loss: 2.1246 - val_accuracy: 0.9281\n",
      "Epoch 23/50\n",
      "40/40 [==============================] - 8s 204ms/step - loss: 1.8218 - accuracy: 0.9284 - val_loss: 1.7096 - val_accuracy: 0.9500\n",
      "Epoch 24/50\n",
      "40/40 [==============================] - 8s 201ms/step - loss: 1.6726 - accuracy: 0.9204 - val_loss: 1.5393 - val_accuracy: 0.9344\n",
      "Epoch 25/50\n",
      "40/40 [==============================] - 8s 202ms/step - loss: 1.4157 - accuracy: 0.9340 - val_loss: 1.2054 - val_accuracy: 0.9531\n",
      "Epoch 26/50\n",
      "40/40 [==============================] - 8s 203ms/step - loss: 1.1661 - accuracy: 0.9268 - val_loss: 0.8852 - val_accuracy: 0.9719\n",
      "Epoch 27/50\n",
      "40/40 [==============================] - 8s 205ms/step - loss: 1.0281 - accuracy: 0.9268 - val_loss: 0.8662 - val_accuracy: 0.9469\n",
      "Epoch 28/50\n",
      "40/40 [==============================] - 8s 201ms/step - loss: 0.8758 - accuracy: 0.9276 - val_loss: 0.8323 - val_accuracy: 0.9281\n",
      "Epoch 29/50\n",
      "40/40 [==============================] - 8s 201ms/step - loss: 0.7388 - accuracy: 0.9403 - val_loss: 0.5759 - val_accuracy: 0.9812\n",
      "Epoch 30/50\n",
      "40/40 [==============================] - 8s 205ms/step - loss: 0.6519 - accuracy: 0.9483 - val_loss: 0.6911 - val_accuracy: 0.9344\n",
      "Epoch 31/50\n",
      "40/40 [==============================] - 8s 207ms/step - loss: 1.0066 - accuracy: 0.9244 - val_loss: 0.9784 - val_accuracy: 0.9375\n",
      "Epoch 32/50\n",
      "40/40 [==============================] - 8s 208ms/step - loss: 1.0402 - accuracy: 0.9165 - val_loss: 0.9133 - val_accuracy: 0.9656\n",
      "Epoch 33/50\n",
      "40/40 [==============================] - 8s 204ms/step - loss: 1.0836 - accuracy: 0.9173 - val_loss: 1.2267 - val_accuracy: 0.9094\n",
      "Epoch 34/50\n",
      "40/40 [==============================] - 8s 205ms/step - loss: 1.2197 - accuracy: 0.9316 - val_loss: 3.3623 - val_accuracy: 0.6969\n",
      "Epoch 35/50\n",
      "40/40 [==============================] - 8s 203ms/step - loss: 1.4811 - accuracy: 0.9236 - val_loss: 1.6794 - val_accuracy: 0.9000\n",
      "Epoch 36/50\n",
      "40/40 [==============================] - 8s 202ms/step - loss: 1.6852 - accuracy: 0.9014 - val_loss: 2.2000 - val_accuracy: 0.8938\n",
      "Epoch 37/50\n",
      "40/40 [==============================] - 8s 204ms/step - loss: 1.8887 - accuracy: 0.9053 - val_loss: 2.7296 - val_accuracy: 0.7781\n",
      "Epoch 38/50\n",
      "40/40 [==============================] - 8s 203ms/step - loss: 1.5158 - accuracy: 0.9244 - val_loss: 1.4285 - val_accuracy: 0.8969\n",
      "Epoch 39/50\n",
      "40/40 [==============================] - 8s 205ms/step - loss: 1.3071 - accuracy: 0.9348 - val_loss: 1.1775 - val_accuracy: 0.9563\n",
      "Epoch 40/50\n",
      "40/40 [==============================] - 8s 200ms/step - loss: 1.1524 - accuracy: 0.9189 - val_loss: 1.5896 - val_accuracy: 0.8687\n",
      "Epoch 41/50\n",
      "40/40 [==============================] - 8s 201ms/step - loss: 1.0246 - accuracy: 0.9340 - val_loss: 1.0302 - val_accuracy: 0.9344\n",
      "Epoch 42/50\n",
      "40/40 [==============================] - 8s 203ms/step - loss: 0.9356 - accuracy: 0.9359 - val_loss: 1.0369 - val_accuracy: 0.9469\n",
      "Epoch 43/50\n",
      "40/40 [==============================] - 8s 200ms/step - loss: 0.7350 - accuracy: 0.9491 - val_loss: 0.8667 - val_accuracy: 0.9406\n",
      "Epoch 44/50\n",
      "40/40 [==============================] - 8s 196ms/step - loss: 0.6887 - accuracy: 0.9403 - val_loss: 0.7804 - val_accuracy: 0.9563\n",
      "Epoch 45/50\n",
      "40/40 [==============================] - 8s 202ms/step - loss: 1.0894 - accuracy: 0.8990 - val_loss: 1.3109 - val_accuracy: 0.8844\n",
      "Epoch 46/50\n",
      "40/40 [==============================] - 8s 198ms/step - loss: 1.2490 - accuracy: 0.9077 - val_loss: 1.1898 - val_accuracy: 0.9187\n",
      "Epoch 47/50\n",
      "40/40 [==============================] - 8s 201ms/step - loss: 1.1390 - accuracy: 0.9276 - val_loss: 2.1424 - val_accuracy: 0.7500\n",
      "Epoch 48/50\n",
      "40/40 [==============================] - 8s 197ms/step - loss: 1.7772 - accuracy: 0.9157 - val_loss: 1.6437 - val_accuracy: 0.9812\n",
      "Epoch 49/50\n",
      "40/40 [==============================] - 8s 199ms/step - loss: 1.5808 - accuracy: 0.9411 - val_loss: 1.2926 - val_accuracy: 0.9750\n",
      "Epoch 50/50\n",
      "40/40 [==============================] - 8s 197ms/step - loss: 1.2963 - accuracy: 0.9403 - val_loss: 1.0607 - val_accuracy: 0.9719\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "with tf.device('/GPU:0'):\n",
    "    history = fifthmodel.fit(\n",
    "        trainDataSet,\n",
    "        steps_per_epoch = trainDataSet.samples // trainDataSet.batch_size,\n",
    "        epochs = num_epochs,\n",
    "        validation_data = validDataSet,\n",
    "        validation_steps = validDataSet.samples // validDataSet.batch_size,\n",
    "        verbose = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 7s 161ms/step - loss: 1.0334 - accuracy: 0.9852\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 1.0607 - accuracy: 0.9719\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 5.2150 - accuracy: 0.3000\n"
     ]
    }
   ],
   "source": [
    "fifthhmodel_trainscore = fifthmodel.evaluate(trainDataSet,steps=trainDataSet.samples // trainDataSet.batch_size)\n",
    "fifthhmodel_validationscore = fifthmodel.evaluate(validDataSet,steps=validDataSet.samples // validDataSet.batch_size)\n",
    "fifthhmodel_testscore = fifthmodel.evaluate(test_generator,steps=test_generator.samples // test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base model accuracy score for the train:  0.99\n",
      "The base model accuracy score for the validation:  0.97\n",
      "======================================================\n",
      "The base model accuracy score for the test:  0.3\n"
     ]
    }
   ],
   "source": [
    "print(\"The base model accuracy score for the train: \",round(fifthhmodel_trainscore[1],2))\n",
    "print(\"The base model accuracy score for the validation: \",round(fifthhmodel_validationscore[1],2))\n",
    "print(\"======================================================\")\n",
    "print(\"The base model accuracy score for the test: \",round(fifthhmodel_testscore[1],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the model is doing really badly on test set even after augmenting the images. We attempt to check what are the images that the model is not predicting correct for error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "fifthmodel_predictions = fifthmodel.predict(test_generator,steps=test_generator.samples // test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generatePredictionDF(test_generator,model):\n",
    "    classpredictions = model.predict(test_generator,steps = test_generator.samples // test_generator.batch_size)\n",
    "    predicted_classes = classpredictions.argmax(axis=1)\n",
    "    true_classes = test_generator.classes\n",
    "    checkprediction = predicted_classes != true_classes\n",
    "\n",
    "    #Generate Pandas Dataframe \n",
    "    df = pd.DataFrame({\"filepaths\": test_generator.filepaths, \"trueclass\": true_classes,\"predicted\": predicted_classes ,\"Correctly Predicted\": checkprediction})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/60 [==============================] - 1s 10ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = generatePredictionDF(test_generator,fifthmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>trueclass</th>\n",
       "      <th>predicted</th>\n",
       "      <th>Correctly Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_sorted\\apple\\apple_77.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_sorted\\apple\\apple_78.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_sorted\\apple\\apple_79.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_sorted\\apple\\apple_80.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_sorted\\apple\\apple_81.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_sorted\\apple\\apple_82.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_sorted\\apple\\apple_83.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_sorted\\apple\\apple_84.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_sorted\\apple\\apple_85.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_sorted\\apple\\apple_86.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_sorted\\apple\\apple_87.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_sorted\\apple\\apple_88.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_sorted\\apple\\apple_89.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test_sorted\\apple\\apple_90.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test_sorted\\apple\\apple_91.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test_sorted\\apple\\apple_92.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test_sorted\\apple\\apple_93.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test_sorted\\apple\\apple_94.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test_sorted\\apple\\apple_95.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test_sorted\\banana\\banana_77.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test_sorted\\banana\\banana_78.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test_sorted\\banana\\banana_79.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test_sorted\\banana\\banana_80.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test_sorted\\banana\\banana_81.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>test_sorted\\banana\\banana_82.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test_sorted\\banana\\banana_83.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>test_sorted\\banana\\banana_84.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test_sorted\\banana\\banana_85.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>test_sorted\\banana\\banana_86.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test_sorted\\banana\\banana_87.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>test_sorted\\banana\\banana_88.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>test_sorted\\banana\\banana_89.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>test_sorted\\banana\\banana_90.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>test_sorted\\banana\\banana_91.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>test_sorted\\banana\\banana_92.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>test_sorted\\banana\\banana_93.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>test_sorted\\banana\\banana_94.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>test_sorted\\mixed\\mixed_21.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>test_sorted\\mixed\\mixed_22.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>test_sorted\\mixed\\mixed_23.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>test_sorted\\mixed\\mixed_24.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>test_sorted\\mixed\\mixed_25.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>test_sorted\\orange\\orange_77.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>test_sorted\\orange\\orange_78.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>test_sorted\\orange\\orange_79.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>test_sorted\\orange\\orange_80.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>test_sorted\\orange\\orange_81.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>test_sorted\\orange\\orange_82.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>test_sorted\\orange\\orange_83.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>test_sorted\\orange\\orange_84.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>test_sorted\\orange\\orange_85.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>test_sorted\\orange\\orange_86.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>test_sorted\\orange\\orange_87.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>test_sorted\\orange\\orange_89.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>test_sorted\\orange\\orange_90.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>test_sorted\\orange\\orange_91.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>test_sorted\\orange\\orange_92.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>test_sorted\\orange\\orange_93.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>test_sorted\\orange\\orange_94.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>test_sorted\\orange\\orange_95.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           filepaths  trueclass  predicted  \\\n",
       "0     test_sorted\\apple\\apple_77.jpg          0          0   \n",
       "1     test_sorted\\apple\\apple_78.jpg          0          3   \n",
       "2     test_sorted\\apple\\apple_79.jpg          0          1   \n",
       "3     test_sorted\\apple\\apple_80.jpg          0          0   \n",
       "4     test_sorted\\apple\\apple_81.jpg          0          0   \n",
       "5     test_sorted\\apple\\apple_82.jpg          0          0   \n",
       "6     test_sorted\\apple\\apple_83.jpg          0          0   \n",
       "7     test_sorted\\apple\\apple_84.jpg          0          3   \n",
       "8     test_sorted\\apple\\apple_85.jpg          0          0   \n",
       "9     test_sorted\\apple\\apple_86.jpg          0          0   \n",
       "10    test_sorted\\apple\\apple_87.jpg          0          0   \n",
       "11    test_sorted\\apple\\apple_88.jpg          0          3   \n",
       "12    test_sorted\\apple\\apple_89.jpg          0          0   \n",
       "13    test_sorted\\apple\\apple_90.jpg          0          0   \n",
       "14    test_sorted\\apple\\apple_91.jpg          0          3   \n",
       "15    test_sorted\\apple\\apple_92.jpg          0          3   \n",
       "16    test_sorted\\apple\\apple_93.jpg          0          0   \n",
       "17    test_sorted\\apple\\apple_94.jpg          0          3   \n",
       "18    test_sorted\\apple\\apple_95.jpg          0          3   \n",
       "19  test_sorted\\banana\\banana_77.jpg          1          0   \n",
       "20  test_sorted\\banana\\banana_78.jpg          1          0   \n",
       "21  test_sorted\\banana\\banana_79.jpg          1          0   \n",
       "22  test_sorted\\banana\\banana_80.jpg          1          0   \n",
       "23  test_sorted\\banana\\banana_81.jpg          1          3   \n",
       "24  test_sorted\\banana\\banana_82.jpg          1          0   \n",
       "25  test_sorted\\banana\\banana_83.jpg          1          1   \n",
       "26  test_sorted\\banana\\banana_84.jpg          1          0   \n",
       "27  test_sorted\\banana\\banana_85.jpg          1          0   \n",
       "28  test_sorted\\banana\\banana_86.jpg          1          3   \n",
       "29  test_sorted\\banana\\banana_87.jpg          1          3   \n",
       "30  test_sorted\\banana\\banana_88.jpg          1          1   \n",
       "31  test_sorted\\banana\\banana_89.jpg          1          3   \n",
       "32  test_sorted\\banana\\banana_90.jpg          1          0   \n",
       "33  test_sorted\\banana\\banana_91.jpg          1          0   \n",
       "34  test_sorted\\banana\\banana_92.jpg          1          0   \n",
       "35  test_sorted\\banana\\banana_93.jpg          1          1   \n",
       "36  test_sorted\\banana\\banana_94.jpg          1          0   \n",
       "37    test_sorted\\mixed\\mixed_21.jpg          2          3   \n",
       "38    test_sorted\\mixed\\mixed_22.jpg          2          0   \n",
       "39    test_sorted\\mixed\\mixed_23.jpg          2          3   \n",
       "40    test_sorted\\mixed\\mixed_24.jpg          2          0   \n",
       "41    test_sorted\\mixed\\mixed_25.jpg          2          0   \n",
       "42  test_sorted\\orange\\orange_77.jpg          3          3   \n",
       "43  test_sorted\\orange\\orange_78.jpg          3          3   \n",
       "44  test_sorted\\orange\\orange_79.jpg          3          3   \n",
       "45  test_sorted\\orange\\orange_80.jpg          3          3   \n",
       "46  test_sorted\\orange\\orange_81.jpg          3          3   \n",
       "47  test_sorted\\orange\\orange_82.jpg          3          3   \n",
       "48  test_sorted\\orange\\orange_83.jpg          3          3   \n",
       "49  test_sorted\\orange\\orange_84.jpg          3          3   \n",
       "50  test_sorted\\orange\\orange_85.jpg          3          3   \n",
       "51  test_sorted\\orange\\orange_86.jpg          3          0   \n",
       "52  test_sorted\\orange\\orange_87.jpg          3          3   \n",
       "53  test_sorted\\orange\\orange_89.jpg          3          1   \n",
       "54  test_sorted\\orange\\orange_90.jpg          3          3   \n",
       "55  test_sorted\\orange\\orange_91.jpg          3          3   \n",
       "56  test_sorted\\orange\\orange_92.jpg          3          3   \n",
       "57  test_sorted\\orange\\orange_93.jpg          3          3   \n",
       "58  test_sorted\\orange\\orange_94.jpg          3          3   \n",
       "59  test_sorted\\orange\\orange_95.jpg          3          3   \n",
       "\n",
       "    Correctly Predicted  \n",
       "0                 False  \n",
       "1                  True  \n",
       "2                  True  \n",
       "3                 False  \n",
       "4                 False  \n",
       "5                 False  \n",
       "6                 False  \n",
       "7                  True  \n",
       "8                 False  \n",
       "9                 False  \n",
       "10                False  \n",
       "11                 True  \n",
       "12                False  \n",
       "13                False  \n",
       "14                 True  \n",
       "15                 True  \n",
       "16                False  \n",
       "17                 True  \n",
       "18                 True  \n",
       "19                 True  \n",
       "20                 True  \n",
       "21                 True  \n",
       "22                 True  \n",
       "23                 True  \n",
       "24                 True  \n",
       "25                False  \n",
       "26                 True  \n",
       "27                 True  \n",
       "28                 True  \n",
       "29                 True  \n",
       "30                False  \n",
       "31                 True  \n",
       "32                 True  \n",
       "33                 True  \n",
       "34                 True  \n",
       "35                False  \n",
       "36                 True  \n",
       "37                 True  \n",
       "38                 True  \n",
       "39                 True  \n",
       "40                 True  \n",
       "41                 True  \n",
       "42                False  \n",
       "43                False  \n",
       "44                False  \n",
       "45                False  \n",
       "46                False  \n",
       "47                False  \n",
       "48                False  \n",
       "49                False  \n",
       "50                False  \n",
       "51                 True  \n",
       "52                False  \n",
       "53                 True  \n",
       "54                False  \n",
       "55                False  \n",
       "56                False  \n",
       "57                False  \n",
       "58                False  \n",
       "59                False  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that the orange class is badly predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sixth Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to improve the model by increasing the dropout rates and also introduct more CNN layers. We will also reduce the learning rate to make the model make more refined adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding batch normalisation to further reduce overfitting\n",
    "sixthmodel = Sequential()\n",
    "\n",
    "sixthmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(image_height, image_width, 3))) # Increased the kernel size of filter \n",
    "sixthmodel.add(BatchNormalization())\n",
    "sixthmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "sixthmodel.add(Dropout(0.2)) # Increased Dropout \n",
    "\n",
    "sixthmodel.add(Conv2D(64, (3, 3), activation='relu', padding='same')) # Increased the kernel size of filter\n",
    "sixthmodel.add(BatchNormalization())\n",
    "sixthmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "sixthmodel.add(Dropout(0.3)) # Increased Dropout \n",
    "\n",
    "sixthmodel.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "sixthmodel.add(BatchNormalization())\n",
    "sixthmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "sixthmodel.add(Dropout(0.4)) # Increased Dropout \n",
    "\n",
    "\n",
    "sixthmodel.add(Flatten())\n",
    "\n",
    "# FC layer\n",
    "sixthmodel.add(Dense(128, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))  # Increased the number of neurons\n",
    "sixthmodel.add(Dropout(0.5))\n",
    "\n",
    "sixthmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "sixthmodel.compile(optimizer=Adam(learning_rate=0.0001), # Lowering the learning rate\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding batch normalisation to further reduce overfitting\n",
    "sixthmodel = Sequential()\n",
    "\n",
    "sixthmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(image_height, image_width, 3))) # Increased the kernel size of filter \n",
    "sixthmodel.add(BatchNormalization())\n",
    "sixthmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "sixthmodel.add(Dropout(0.2)) # Increased Dropout \n",
    "\n",
    "sixthmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same')) # Increased the kernel size of filter\n",
    "sixthmodel.add(BatchNormalization())\n",
    "sixthmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "sixthmodel.add(Dropout(0.3)) # Increased Dropout \n",
    "\n",
    "\n",
    "sixthmodel.add(Flatten())\n",
    "\n",
    "# FC layer\n",
    "sixthmodel.add(Dense(32, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01), activation='relu'))  # Increased the number of neurons\n",
    "sixthmodel.add(Dropout(0.5)) # Increased Dropout\n",
    "\n",
    "sixthmodel.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "sixthmodel.compile(optimizer=Adam(learning_rate=0.0001), # Lowered learning rate\n",
    "                    loss='categorical_crossentropy',\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 193 images belonging to 4 classes.\n",
      "Found 47 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Inputing images using ImageDataGenerator without augmentation to get baseline\n",
    "datagen = ImageDataGenerator(\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "\n",
    "trainDataSet = trainDataSet = datagen.flow_from_directory(\n",
    "    target_size=(image_height, image_width),\n",
    "    directory=\"train_sorted\",\n",
    "    subset = \"training\",\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = True,\n",
    "    batch_size = 8 # Reduce batch size\n",
    ")\n",
    "\n",
    "validDataSet = validDataSet = datagen.flow_from_directory(\n",
    "    target_size=(image_height, image_width),\n",
    "    directory=\"train_sorted\",\n",
    "    subset = \"validation\",\n",
    "    class_mode = \"categorical\",\n",
    "    shuffle = True,\n",
    "    batch_size = 8 # Reduce batch size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "24/24 [==============================] - 2s 71ms/step - loss: 2.7935 - accuracy: 0.4324 - val_loss: 1.9475 - val_accuracy: 0.4000\n",
      "Epoch 2/20\n",
      "24/24 [==============================] - 2s 62ms/step - loss: 1.6601 - accuracy: 0.5297 - val_loss: 1.5067 - val_accuracy: 0.6500\n",
      "Epoch 3/20\n",
      "24/24 [==============================] - 2s 66ms/step - loss: 1.4736 - accuracy: 0.6541 - val_loss: 1.4282 - val_accuracy: 0.6250\n",
      "Epoch 4/20\n",
      "24/24 [==============================] - 2s 66ms/step - loss: 1.4630 - accuracy: 0.6595 - val_loss: 1.2117 - val_accuracy: 0.8500\n",
      "Epoch 5/20\n",
      "24/24 [==============================] - 2s 66ms/step - loss: 1.2702 - accuracy: 0.7622 - val_loss: 1.1122 - val_accuracy: 0.8250\n",
      "Epoch 6/20\n",
      "24/24 [==============================] - 2s 63ms/step - loss: 1.2627 - accuracy: 0.7405 - val_loss: 1.2504 - val_accuracy: 0.8000\n",
      "Epoch 7/20\n",
      "24/24 [==============================] - 2s 64ms/step - loss: 1.1310 - accuracy: 0.7865 - val_loss: 1.1532 - val_accuracy: 0.8000\n",
      "Epoch 8/20\n",
      "24/24 [==============================] - 2s 65ms/step - loss: 1.1472 - accuracy: 0.7892 - val_loss: 0.9516 - val_accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "24/24 [==============================] - 2s 65ms/step - loss: 1.1386 - accuracy: 0.8270 - val_loss: 1.1903 - val_accuracy: 0.8250\n",
      "Epoch 10/20\n",
      "24/24 [==============================] - 2s 66ms/step - loss: 1.0872 - accuracy: 0.7838 - val_loss: 1.0989 - val_accuracy: 0.7500\n",
      "Epoch 11/20\n",
      "24/24 [==============================] - 2s 64ms/step - loss: 1.0950 - accuracy: 0.8108 - val_loss: 1.0903 - val_accuracy: 0.8500\n",
      "Epoch 12/20\n",
      "24/24 [==============================] - 1s 61ms/step - loss: 1.0965 - accuracy: 0.8216 - val_loss: 1.0392 - val_accuracy: 0.8500\n",
      "Epoch 13/20\n",
      "24/24 [==============================] - 2s 67ms/step - loss: 1.0301 - accuracy: 0.8378 - val_loss: 0.9512 - val_accuracy: 0.9250\n",
      "Epoch 14/20\n",
      "24/24 [==============================] - 1s 60ms/step - loss: 0.9133 - accuracy: 0.8973 - val_loss: 1.0744 - val_accuracy: 0.8500\n",
      "Epoch 15/20\n",
      "24/24 [==============================] - 2s 66ms/step - loss: 0.9109 - accuracy: 0.8757 - val_loss: 0.9997 - val_accuracy: 0.8750\n",
      "Epoch 16/20\n",
      "24/24 [==============================] - 2s 60ms/step - loss: 0.9713 - accuracy: 0.8541 - val_loss: 1.0075 - val_accuracy: 0.8750\n",
      "Epoch 17/20\n",
      "24/24 [==============================] - 2s 65ms/step - loss: 0.9008 - accuracy: 0.8865 - val_loss: 1.1129 - val_accuracy: 0.8750\n",
      "Epoch 18/20\n",
      "24/24 [==============================] - 2s 68ms/step - loss: 0.8646 - accuracy: 0.8906 - val_loss: 1.2557 - val_accuracy: 0.8250\n",
      "Epoch 19/20\n",
      "24/24 [==============================] - 2s 63ms/step - loss: 0.9174 - accuracy: 0.8595 - val_loss: 1.1204 - val_accuracy: 0.8500\n",
      "Epoch 20/20\n",
      "24/24 [==============================] - 2s 67ms/step - loss: 0.8637 - accuracy: 0.8703 - val_loss: 1.1462 - val_accuracy: 0.8750\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "with tf.device('/GPU:0'):\n",
    "    history = sixthmodel.fit(\n",
    "        trainDataSet,\n",
    "        steps_per_epoch = trainDataSet.samples // trainDataSet.batch_size,\n",
    "        epochs = num_epochs,\n",
    "        validation_data = validDataSet,\n",
    "        validation_steps = validDataSet.samples // validDataSet.batch_size,\n",
    "        verbose = 1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 1s 52ms/step - loss: 0.6327 - accuracy: 0.9740\n",
      "5/5 [==============================] - 0s 50ms/step - loss: 1.0662 - accuracy: 0.8500\n",
      "60/60 [==============================] - 0s 8ms/step - loss: 8.2129 - accuracy: 0.3167\n"
     ]
    }
   ],
   "source": [
    "sixthmodel_trainscore = sixthmodel.evaluate(trainDataSet,steps=trainDataSet.samples // trainDataSet.batch_size)\n",
    "sixthmodel_validationscore = sixthmodel.evaluate(validDataSet,steps=validDataSet.samples // validDataSet.batch_size)\n",
    "sixthmodel_testscore = sixthmodel.evaluate(test_generator,steps=test_generator.samples // test_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The base model accuracy score for the train:  0.97\n",
      "The base model accuracy score for the validation:  0.85\n",
      "======================================================\n",
      "The base model accuracy score for the test:  0.32\n"
     ]
    }
   ],
   "source": [
    "print(\"The base model accuracy score for the train: \",round(sixthmodel_trainscore[1],2))\n",
    "print(\"The base model accuracy score for the validation: \",round(sixthmodel_validationscore[1],2))\n",
    "print(\"======================================================\")\n",
    "print(\"The base model accuracy score for the test: \",round(sixthmodel_testscore[1],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO7CHMy1P+OGJQusiMjCWiR",
   "gpuType": "V100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
